{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Импортируем необходимые библиотеки:"
      ],
      "metadata": {
        "id": "B68LhzINrkR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "from keras import layers, models, optimizers\n",
        "from keras.applications import MobileNet\n",
        "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input\n",
        "from keras import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "Ikv8HO0MrjeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка датасета и его распаковка:"
      ],
      "metadata": {
        "id": "cSfrc9mPrsc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.yandexcloud.net/academy.ai/cat-and-dog.zip\n",
        "!unzip -qo \"cat-and-dog\" -d ./temp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYUJXZIHrr12",
        "outputId": "3369ffe0-5c33-4ed9-f181-8fd2178ccf2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-13 18:17:10--  https://storage.yandexcloud.net/academy.ai/cat-and-dog.zip\n",
            "Resolving storage.yandexcloud.net (storage.yandexcloud.net)... 213.180.193.243, 2a02:6b8::1d9\n",
            "Connecting to storage.yandexcloud.net (storage.yandexcloud.net)|213.180.193.243|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228082266 (218M) [application/x-zip-compressed]\n",
            "Saving to: ‘cat-and-dog.zip’\n",
            "\n",
            "cat-and-dog.zip     100%[===================>] 217.52M  32.2MB/s    in 7.9s    \n",
            "\n",
            "2025-04-13 18:17:19 (27.7 MB/s) - ‘cat-and-dog.zip’ saved [228082266/228082266]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим некоторые переменные для дальнейшей работы с изображениями в датасете:"
      ],
      "metadata": {
        "id": "7w5nreDox3FS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_WIDTH, IMG_HEIGHT = 150, 150 #параметры изображений\n",
        "\n",
        "IMAGE_PATH = './temp/training_set/training_set/' #определение путей к данным\n",
        "BASE_DIR = './dataset/'\n",
        "\n",
        "CLASS_LIST = sorted(os.listdir(IMAGE_PATH)) #анализ классов данных\n",
        "CLASS_COUNT = len(CLASS_LIST)\n",
        "NUM_CLASSES = CLASS_COUNT"
      ],
      "metadata": {
        "id": "ca0Tas9tx1P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выполним стандартную практику в машинном обучении - определим файловую структуру:"
      ],
      "metadata": {
        "id": "J8DxEbST14Ur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(BASE_DIR): #удаляем старую папку, если существует\n",
        "    shutil.rmtree(BASE_DIR)\n",
        "\n",
        "os.mkdir(BASE_DIR) #создание новой базовой директории\n",
        "\n",
        "#создаем подпапок\n",
        "train_dir = os.path.join(BASE_DIR, 'train')\n",
        "os.mkdir(train_dir)\n",
        "validation_dir = os.path.join(BASE_DIR, 'validation')\n",
        "os.mkdir(validation_dir)\n",
        "test_dir = os.path.join(BASE_DIR, 'test')\n",
        "os.mkdir(test_dir)"
      ],
      "metadata": {
        "id": "kuOk1-Ey120c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим функцию создания подвыборок (папок с файлами). В этой функции используется `shutil.copyfile()` — метод модуля *shutil* в Python, который используется для копирования содержимого исходного файла в целевой. При этом метаданные файла не копируются."
      ],
      "metadata": {
        "id": "UMUlVSLKHl1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(img_path, new_path, class_name, start_index, end_index):\n",
        "    src_path = os.path.join(img_path, class_name)\n",
        "    dst_path = os.path.join(new_path, class_name)\n",
        "    os.mkdir(dst_path)\n",
        "\n",
        "    class_files = os.listdir(src_path)\n",
        "    for fname in class_files[start_index:end_index]:\n",
        "        src = os.path.join(src_path, fname)\n",
        "        dst = os.path.join(dst_path, fname)\n",
        "        shutil.copyfile(src, dst)"
      ],
      "metadata": {
        "id": "AKT_76UxH0Ok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Далее выполним разделение исходного датасета на тренировочную, валидационную и тестовую выборки для каждого класса изображений:"
      ],
      "metadata": {
        "id": "9Bn-0mBLKaFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#распределение изображений\n",
        "for class_label in range(CLASS_COUNT):\n",
        "    class_name = CLASS_LIST[class_label]\n",
        "    class_files = os.listdir(os.path.join(IMAGE_PATH, class_name))\n",
        "    total_samples = len(class_files)\n",
        "\n",
        "    train_end = int(total_samples * 0.6)\n",
        "    validation_end = train_end + int(total_samples * 0.2)\n",
        "\n",
        "    create_dataset(IMAGE_PATH, train_dir, class_name, 0, train_end) #тренировочная выборка\n",
        "    create_dataset(IMAGE_PATH, validation_dir, class_name, train_end, validation_end) #валидационная выборка\n",
        "    create_dataset(IMAGE_PATH, test_dir, class_name, validation_end, total_samples) #контрольная выборка"
      ],
      "metadata": {
        "id": "4THvnJntJ_N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим модель нейронной сети для классификации изображений с использованием предобученной **MobileNet** в качестве базового слоя. **MobileNet** — предобученная **CNN** (уже обучена на **ImageNet**).\n",
        "\n",
        "`include_top=False` — не включаем верхние (классификационные) слои **MobileNet**\n",
        "\n",
        "**GlobalAveragePooling2D** — заменяет классический **Flatten**, усредняя значения по каждому каналу, уменьшает количество параметров и предотвращает переобучение."
      ],
      "metadata": {
        "id": "CoiWxFd9KafU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#функция создания модели\n",
        "def model_maker():\n",
        "    base_model = MobileNet(include_top=False, input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
        "\n",
        "    for layer in base_model.layers[:]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    input = Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
        "    custom_model = base_model(input)\n",
        "    custom_model = GlobalAveragePooling2D()(custom_model)\n",
        "    custom_model = Dense(64, activation='relu')(custom_model)\n",
        "    custom_model = Dropout(0.5)(custom_model)\n",
        "    predictions = Dense(NUM_CLASSES, activation='softmax')(custom_model)\n",
        "\n",
        "    return Model(inputs=input, outputs=predictions)"
      ],
      "metadata": {
        "id": "znBT3LkRKHX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим и настроим модель нейронной сети перед началом обучения. В качестве оптимизатора будем использовать **Adam**. Выберем кросс-энтропию, которая является стандартной функцией потерь для задач классификации:"
      ],
      "metadata": {
        "id": "oqN6ulycKa3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#инициализация и компиляция модели\n",
        "model = model_maker()\n",
        "model.compile(optimizer=optimizers.Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "I0xK7iyGKJUf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "592b26d6-30c6-439b-c4ff-b00d2de7e850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-b4310b25c3b9>:3: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base_model = MobileNet(include_top=False, input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
            "\u001b[1m17225924/17225924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим генераторы данных для тренировочного, валидационного и контрольного наборов, применяя *аугментацию данных* только к тренировочным изображениям:"
      ],
      "metadata": {
        "id": "dnn3ZDXaKbNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#создание генераторов данных с аугментацией для тренировочного набора\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255, #нормализация пикселей [0,255] -> [0,1]\n",
        "    rotation_range=20, #cлучайный поворот\n",
        "    width_shift_range=0.2, #cлучайный сдвиг по ширине\n",
        "    height_shift_range=0.2, #cлучайный сдвиг по высоте\n",
        "    shear_range=0.2, #cлучайный сдвиг (искажение)\n",
        "    zoom_range=0.2, #cлучайное масштабирование [0.8, 1.2]\n",
        "    horizontal_flip=True, #cлучайное зеркальное отражение\n",
        "    fill_mode='nearest' #заполнение новых пикселей при трансформациях\n",
        ")\n",
        "\n",
        "#без аугментации для валидации и теста\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "pO4BL4CAKNEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Следующий код создает генераторы данных, которые потоково загружают изображения из соответствующих директорий, применяя заданные преобразования и подготавливая данные для обучения нейронной сети:"
      ],
      "metadata": {
        "id": "5UPswevWKbrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "    batch_size=20,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "    batch_size=20,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "    batch_size=20,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "id": "6ucqH4hMKQUe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b67cb40-76c7-47ee-a59c-7c22cf133bda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4803 images belonging to 2 classes.\n",
            "Found 1601 images belonging to 2 classes.\n",
            "Found 1601 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EarlyStopping** - ранняя остановка обучения. Это нужно, чтобы автоматически останавливать обучение, когда модель перестаёт улучшаться, предотвращая переобучение и экономя время. Мониторит метрику `val_accuracy` (точность на валидационных данных). Если точность не улучшается в течение `patience=3` эпох — обучение останавливается. `restore_best_weights=True` — после остановки модель возвращает веса, которые давали наилучшую `val_accuracy`, а не последние веса."
      ],
      "metadata": {
        "id": "MXpcNJFpKcGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "FltHg2ynKTRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Далее извлечём общее количество изображений в каждом наборе данных (тренировочном, валидационном и контрольном) из созданных ранее генераторов:"
      ],
      "metadata": {
        "id": "7DeJdbe8KckJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#получаем количество образцов из генераторов\n",
        "train_samples = train_generator.samples\n",
        "validation_samples = validation_generator.samples\n",
        "test_samples = test_generator.samples"
      ],
      "metadata": {
        "id": "S_cOY6tHKUMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выполним обучение нейронной сети с использованием созданных генераторов данных:"
      ],
      "metadata": {
        "id": "dpv8CWdMKc4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#обучение модели\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_samples // 20, #количество шагов за эпоху\n",
        "    epochs=30,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[early_stopping],\n",
        "    validation_steps=validation_samples // 20 #количество валидационных шагов\n",
        ")"
      ],
      "metadata": {
        "id": "MYfMJp-1KV4X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04cd9a6a-ee0d-46c5-f181-b68b37b88310"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 551ms/step - accuracy: 0.8435 - loss: 0.4417 - val_accuracy: 0.9588 - val_loss: 0.1045\n",
            "Epoch 2/30\n",
            "\u001b[1m  1/240\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:05\u001b[0m 275ms/step - accuracy: 0.9000 - loss: 0.1186"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 107ms/step - accuracy: 0.9000 - loss: 0.1186 - val_accuracy: 0.9575 - val_loss: 0.1104\n",
            "Epoch 3/30\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 543ms/step - accuracy: 0.9368 - loss: 0.1576 - val_accuracy: 0.9631 - val_loss: 0.0899\n",
            "Epoch 4/30\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 170ms/step - accuracy: 0.9000 - loss: 0.1516 - val_accuracy: 0.9606 - val_loss: 0.0918\n",
            "Epoch 5/30\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 590ms/step - accuracy: 0.9380 - loss: 0.1519 - val_accuracy: 0.9656 - val_loss: 0.0933\n",
            "Epoch 6/30\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 105ms/step - accuracy: 0.9500 - loss: 0.1195 - val_accuracy: 0.9644 - val_loss: 0.0962\n",
            "Epoch 7/30\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 529ms/step - accuracy: 0.9409 - loss: 0.1477 - val_accuracy: 0.9656 - val_loss: 0.0979\n",
            "Epoch 8/30\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 0.0119 - val_accuracy: 0.9650 - val_loss: 0.0973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выполним финальную оценку обученной модели на тестовом наборе данных, который модель никогда не видела во время обучения:"
      ],
      "metadata": {
        "id": "GhX6KOHFKdNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#точность контрольной выборки\n",
        "test_loss, test_acc = model.evaluate(test_generator, steps=test_samples // 20)\n",
        "print(f'Точность контрольной выборки: {test_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evSIJ1EEgb1x",
        "outputId": "46b3542c-d494-4eb3-eeee-bbc183835d29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 324ms/step - accuracy: 0.9641 - loss: 0.0786\n",
            "Точность контрольной выборки: 0.9700000286102295\n"
          ]
        }
      ]
    }
  ]
}